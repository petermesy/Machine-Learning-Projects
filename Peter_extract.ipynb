{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbo5ONdkfOqqjETPFnxnF4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/petermesy/Machine-Learning-Projects/blob/main/Peter_extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAF2AA7RC8_R",
        "outputId": "a8ab4c96-3c52-4d7c-96d7-c9104d52705f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.6)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.11/dist-packages (8.0.0)\n",
            "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250327)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Requirement already satisfied: primp>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (0.14.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n"
          ]
        }
      ],
      "source": [
        "pip install pdfplumber pytesseract pdf2image langdetect duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import pdfplumber\n",
        "from langdetect import detect\n",
        "from bs4 import BeautifulSoup\n",
        "from duckduckgo_search import DDGS\n",
        "from urllib.parse import urlparse\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "import json"
      ],
      "metadata": {
        "id": "wLVGua3tDQm9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DOWNLOAD_FOLDER = \"Ethio_laws_pdf\"\n",
        "os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)"
      ],
      "metadata": {
        "id": "IHJbUF4YDt_w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_pdf_urls(query, max_results=1000):\n",
        "    pdf_urls = []\n",
        "    with DDGS() as ddgs:\n",
        "        for result in ddgs.text(query + \" filetype:pdf\", max_results=max_results):\n",
        "            url = result.get(\"href\") or result.get(\"url\")\n",
        "            if url and url.lower().endswith(\".pdf\"):\n",
        "                pdf_urls.append(url)\n",
        "    return pdf_urls"
      ],
      "metadata": {
        "id": "Zih171uDD_GZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_pdf(url, folder):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=None)\n",
        "        if response.status_code == 200 and 'application/pdf' in response.headers.get('Content-Type', ''):\n",
        "            filename = os.path.basename(urlparse(url).path)\n",
        "            filepath = os.path.join(folder, filename)\n",
        "            with open(filepath, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"Downloaded: {filename}\")\n",
        "        else:\n",
        "            print(f\"Skipped (not a valid PDF): {url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {url}: {e}\")"
      ],
      "metadata": {
        "id": "xgIPzJ-yECUl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_and_detect_language(pdf_path):\n",
        "    try:\n",
        "        text = \"\"\n",
        "        # Try extracting text using pdfplumber\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() or \"\"\n",
        "\n",
        "        # If no text is extracted, use OCR\n",
        "        if not text.strip():\n",
        "            print(f\"No text found in {pdf_path}. Using OCR...\")\n",
        "            images = convert_from_path(pdf_path)\n",
        "            for image in images:\n",
        "                text += pytesseract.image_to_string(image, lang=\"eng+amh\")  # Add Amharic OCR if needed\n",
        "\n",
        "        # Detect language\n",
        "        language = detect(text)\n",
        "        return text, language\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract text from {pdf_path}: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "VRwgs-KqEFXH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Change the search query to target Amharic PDFs\n",
        "    search_query = \"የፍትህ አዲስ ደንብ አዲስ ሕግ የፌዴራል ሕጎች filetype:pdf\"\n",
        "    pdf_links = search_pdf_urls(search_query, max_results=1000)\n",
        "\n",
        "    # Save PDF links to a JSON file\n",
        "    pdf_links_file = os.path.join(DOWNLOAD_FOLDER, \"pdf_links.json\")\n",
        "    with open(pdf_links_file, \"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(pdf_links, json_file, ensure_ascii=False, indent=4)\n",
        "    print(f\"PDF links saved to: {pdf_links_file}\")\n",
        "\n",
        "    # Download PDFs\n",
        "    for link in pdf_links:\n",
        "        download_pdf(link, DOWNLOAD_FOLDER)\n",
        "\n",
        "    # Extract text and detect language for each downloaded PDF\n",
        "    for filename in os.listdir(DOWNLOAD_FOLDER):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            filepath = os.path.join(DOWNLOAD_FOLDER, filename)\n",
        "            text, language = extract_text_and_detect_language(filepath)\n",
        "            if text and language:\n",
        "                print(f\"Extracted Text from {filename}:\\n{text[:100]}...\")  # Print first 100 characters of extracted text\n",
        "                output_filename = os.path.splitext(filename)[0] + \".txt\"  # Replace .pdf with .txt\n",
        "                output_filepath = os.path.join(DOWNLOAD_FOLDER, output_filename)\n",
        "                with open(output_filepath, \"w\", encoding=\"utf-8\") as text_file:\n",
        "                    text_file.write(text)\n",
        "                print(f\"Extracted text saved to: {output_filepath}\")\n",
        "                print(f\"Detected Language: {language}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXyvNuG2EIbC",
        "outputId": "14356a0c-403a-43c1-fc8f-285e2dc0678e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF links saved to: Ethio_laws_pdf/pdf_links.json\n",
            "Downloaded: ethiopias-transitional-justice-policy-.pdf\n",
            "Downloaded: 7802d845-49a8-4249-a58a-eb8c41b06646.pdf\n",
            "Skipped (not a valid PDF): https://www.lawethiopia.com/images/addis+ababa/Regulation+Number+125-2022+Addis+Ababa+prosecutors+regulation.pdf\n",
            "Skipped (not a valid PDF): https://habeshadvocates.com/Pdf-Files/304253.pdf\n",
            "Downloaded: ETH101059.pdf\n",
            "Downloaded: transitional-justice-draft-stamped.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLX0iJGsEL8U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}